s_temp = c(s_temp,syscore)
sbar_temp = c(sbar_temp,sbarscore)
}
svec = c(svec,mean(s_temp))
sbarvec = c(sbarvec,mean(sbar_temp))
}
plot(nvec,svec,type="l" ,
xlab="Number of nodes" ,ylab="S" ,
ylim=c(0,max(svec)) ,lwd=3,col="red")
plot(nvec,sbarvec ,type="l" ,
xlab="Number of nodes" ,ylab="S_Avg" ,
ylim=c(0,max(sbarvec)) ,lwd=3,col="red")
install.packages("neuralnet")
library(grid)
library(MASS)
library(neuralnet)
names(infert)
summary(infert)
res = glm(case ~ age+parity+induced+spontaneous,family=binomial(link="logit"), data=infert)
summary(res)
nn = neuralnet(case~age+parity+induced+spontaneous,hidden=2,data=infert)
nn
head(cbind(nn$covariate,nn$net.result[[1]]))
cor(cbind(nn$net.result[[1]],res$fitted.values))
nn2 = neuralnet(case~age+parity+induced+spontaneous,
hidden=2,algorithm="rprop+",data=infert)
nn2 = neuralnet(case~age+parity+induced+spontaneous,hidden=2,algorithm="rprop+",data=infert)
>
cor(cbind(nn2$net.result[[1]],res$fitted.values))
cor(cbind(nn2$net.result[[1]],nn$fitted.result[[1]]))
compute(nn,covariate=matrix(c(30,1,0,1),1,4))
confidence.interval(nn,alpha=0.10)
confidence.interval(nn,alpha=0.5)
confidence.interval[nn,alpha=0.5]
confidence.interval[nn,alpha=0.10]
confidence.interval(nn,alpha=0.10)
library(nnet)
confidence.interval(nn,alpha=0.10)
res = glm(case ~ age+parity+induced+spontaneous,family=binomial(link="logit"), data=infert)
summary(res)
nn = neuralnet(case~age+parity+induced+spontaneous,hidden=2,data=infert)
library(neuralnet)
nn = neuralnet(case~age+parity+induced+spontaneous,hidden=2,data=infert)
res = glm(case ~ age+parity+induced+spontaneous,family=binomial(link="logit"), data=infert)
summary(res)
nn = neuralnet(case~age+parity+induced+spontaneous,hidden=2,data=infert)
nn
head(cbind(nn$covariate,nn$net.result[[1]]))
cor(cbind(nn$net.result[[1]],res$fitted.values))
nn2 = neuralnet(case~age+parity+induced+spontaneous,hidden=2,algorithm="rprop+",data=infert)
cor(cbind(nn2$net.result[[1]],res$fitted.values))
cor(cbind(nn2$net.result[[1]],nn$fitted.result[[1]]))
compute(nn,covariate=matrix(c(30,1,0,1),1,4))
confidence.interval(nn,alpha=0.10)
nn = neuralnet(case~age+parity+induced+spontaneous,hidden=2,data=infert,err.fct = "ce",     # cross-entropy
linear.output = FALSE,
likelihood = TRUE)
nn = neuralnet(case~age+parity+induced+spontaneous,hidden=2,data=infert,err.fct = "ce",linear.output = FALSE,likelihood = TRUE)
nn
head(cbind(nn$covariate,nn$net.result[[1]]))
cor(cbind(nn$net.result[[1]],res$fitted.values))
nn2 = neuralnet(case~age+parity+induced+spontaneous,hidden=2,algorithm="rprop+",data=infert)
cor(cbind(nn2$net.result[[1]],res$fitted.values))
cor(cbind(nn2$net.result[[1]],nn$fitted.result[[1]]))
compute(nn,covariate=matrix(c(30,1,0,1),1,4))
confidence.interval(nn,alpha=0.10)
confidence.interval(nn,alpha=0.95)
library(nnet)
nn3 = nnet(case~age+parity+induced+spontaneous,data=infert,size=2)
nn3
nn3.out = predict(nn3)
dim(nn3.out)
cor(cbind(nn$fitted.result[[1]], nn3.out))
data(iris)
ir = rbind(iris3[ , ,1], iris3[ , ,2], iris3[ , ,3])
targets = class.ind(c(rep("s" , 50), rep("c" , 50), rep("v" , 50)))
samp= c(sample(1:50,25), sample(51:100,25), sample(101:150,25))
ir1 = nnet(ir[samp,], targets[samp,],size = 2, rang = 0.1,
decay = 5e 4, maxit = 200)
ir1 = nnet(ir[samp,], targets[samp,],size = 2, rang = 0.1,
decay = 5e-4, maxit = 200)
samp= c(sample(1:50,25), sample(51:100,25), sample(101:150,25))
ir1 = nnet(ir[samp,], targets[samp,],size = 2, rang = 0.1,
decay = 5e-4, maxit = 200)
orig =max.col(targets[ samp,])
orig =max.col(targets[samp,])
orig
pred =max.col(predict(ir1, ir[ samp,]))
pred
table(orig,pred)
asbrec = function(w,p) {
#w: payoffs
#p: probabilities
#BASIC SETUP
N= length(w)
maxloss = sum(w)
bucket = c(0,seq(maxloss))
LP=matrix(0,N,maxloss+1) #probability grid over losses
#DO FIRST FIRM
LP[1,1] = 1 p[1];
asbrec = function(w,p) {
#w: payoffs
#p: probabilities
#BASIC SETUP
N= length(w)
maxloss = sum(w)
bucket = c(0,seq(maxloss))
LP=matrix(0,N,maxloss+1) #probability grid over losses
#DO FIRST FIRM
LP[1,1] = 1-p[1];
LP[1,w[1]+1] =p[1];
#LOOP OVER REMAINING FIRMS
for (i in seq(2,N)) {
for ( j in seq(maxloss+1)) {
LP[i,j ] =LP[i 1,j ]*(1 p[i ])
asbrec = function(w,p) {
#w: payoffs
#p: probabilities
#BASIC SETUP
N= length(w)
maxloss = sum(w)
bucket = c(0,seq(maxloss))
LP=matrix(0,N,maxloss+1) #probability grid over losses
#DO FIRST FIRM
LP[1,1] = 1-p[1];
LP[1,w[1]+1] =p[1];
#LOOP OVER REMAINING FIRMS
for (i in seq(2,N)) {
for ( j in seq(maxloss+1)) {
LP[i,j ] =LP[i-1,j ]*(1-p[i])
if (bucket[j] w[i] >= 0) {
asbrec = function(w,p) {
#w: payoffs
#p: probabilities
#BASIC SETUP
N= length(w)
maxloss = sum(w)
bucket = c(0,seq(maxloss))
LP=matrix(0,N,maxloss+1) #probability grid over losses
#DO FIRST FIRM
LP[1,1] = 1-p[1];
LP[1,w[1]+1] =p[1];
#LOOP OVER REMAINING FIRMS
for (i in seq(2,N)) {
for ( j in seq(maxloss+1)) {
LP[i,j ] =LP[i-1,j ]*(1-p[i])
if (bucket[j]-w[i] >= 0) {
LP[i,j] =LP[i,j]+LP[i-1,j-w[i]]*p[i]
}
}
asbrec = function(w,p) {
#w: payoffs
#p: probabilities
#BASIC SETUP
N= length(w)
maxloss = sum(w)
bucket = c(0,seq(maxloss))
LP=matrix(0,N,maxloss+1) #probability grid over losses
#DO FIRST FIRM
LP[1,1] = 1-p[1];
LP[1,w[1]+1] =p[1];
#LOOP OVER REMAINING FIRMS
for (i in seq(2,N)) {
for ( j in seq(maxloss+1)) {
LP[i,j ] =LP[i-1,j ]*(1-p[i])
if (bucket[j]-w[i] >= 0) {
LP[i,j] =LP[i,j]+LP[i-1,j-w[i]]*p[i]
}
}
}
lossprobs =LP[N,]
print(t(LP))
result =matrix(c(bucket , lossprobs) ,(maxloss+1),2)
}
w= c(5,8,4,2,1)
p= array(1/length(w) ,length(w))
res = asbrec(w,p)
print(res)
print(sum(res[ ,2]))
barplot(res[ ,2] ,names.arg=res[ ,1] ,
xlab="portfolio value" ,ylab="probability")
>
barplot(res[ ,2] ,names.arg=res[ ,1] ,
xlab="portfolio value" ,ylab="probability")
w= c(5,8,4,2,1)
p= array(1/length(w),length(w))
res = asbrec(w,p)
asbrec = function(w,p) {
#w: payoffs
#p: probabilities
#BASIC SETUP
N= length(w)
maxloss = sum(w)
bucket = c(0,seq(maxloss))
LP=matrix(0,N,maxloss+1) #probability grid over losses
#DO FIRST FIRM
LP[1,1] = 1-p[1];
LP[1,w[1]+1] =p[1];
#LOOP OVER REMAINING FIRMS
for (i in seq(2,N)) {
for ( j in seq(maxloss+1)) {
LP[i,j] =LP[i-1,j]*(1-p[i])
if (bucket[j]-w[i] >= 0) {
LP[i,j] =LP[i,j]+LP[i-1,j-w[i]]*p[i]
}
}
}
#FINISH UP
lossprobs =LP[N,]
print(t(LP))
result =matrix(c(bucket,lossprobs),(maxloss+1),2)
}
w= c(5,8,4,2,1)
p= array(1/length(w),length(w))
res = asbrec(w,p)
print(res)
print(sum(res[,2]))
barplot(res[,2],names.arg=res[ ,1],
xlab="portfolio value",ylab="probability")
digiprob = function(L,q,rho) {
dx = 0.1
x = seq( 40,40)*dx
fx = dnorm(x)*dx
fx = fx/sum(fx)
maxloss = sum(L)
bucket = c(0,seq(maxloss))
totp = array(0,(maxloss+1))
for (i in seq(length(x))) {
p=pnorm((qnorm(q) rho*x[i ]) /sqrt(1 rho^2))
digiprob = function(L,q,rho) {
dx = 0.1
x = seq( 40,40)*dx
fx = dnorm(x)*dx
fx = fx/sum(fx)
maxloss = sum(L)
bucket = c(0,seq(maxloss))
totp = array(0,(maxloss+1))
for (i in seq(length(x))) {
p=pnorm((qnorm(q)-rho*x[i ]) /sqrt(1-rho^2))
ldist = asbrec(L,p)
totp = totp + ldist[ ,2]*fx[i]
}
result =matrix(c(bucket, totp),(maxloss+1),2)
}
w= c(5,8,4,2,1)
q= c(0.1,0.2,0.1,0.05,0.15)
rho = 0.25
res1 = digiprob(w,q,rho)
rho = 0.75
res2 = digiprob(w,q,rho)
par(mfrow=c(2,1))
barplot(res1[ ,2] ,names.arg=res1[ ,1] ,xlab="portfolio value" ,
ylab="probability" ,main="rho = 0.25")
barplot(res2[ ,2] ,names.arg=res2[ ,1] ,xlab="portfolio value" ,
ylab="probability" ,main="rho = 0.75")
par(mfrow=c(5,4,2,1))
par(mfrow=c(2,1))
barplot(res1[ ,1],names.arg=res1[ ,1],xlab="portfolio value",
ylab="probability",main="rho = 0.25")
par(mfrow=c(2,1))
barplot(res1[ ,1],names.arg=res1[ ,1],xlab="portfolio value",
ylab="probability",cex.names=0.7, main="rho = 0.25")
cbind(res1, res2)
par(mfrow=c(2,1))
barplot(res1[ ,2],names.arg=res1[ ,1],xlab="portfolio value",
ylab="probability")
par(mfrow=c(2,1))
barplot(res1[,2],names.arg=res1[,1], xlab="portfolio value",
ylab="probability")
par(mfrow=c(2,1))
barplot(res1[,2],names.arg=res1[,1], xlab="portfolio value",
ylab="probability")
barplot(res2[,2],names.arg=res2[,0.5],xlab="portfolio value",
ylab="probability")
barplot(res1[,2],names.arg=res1[,1],las=2, xlab="portfolio value",
ylab="probability")
par(mar=c(5,4,2,1))
barplot(res1[,2],names.arg=res1[,1], xlab="portfolio value",
ylab="probability")
barplot(res2[,2],names.arg=res2[,1], xlab="portfolio value",
ylab="probability")
par(mar=c(5,4,2,1))
barplot(res1[,2],names.arg=res1[,1], cex.names=0.7,xlab="portfolio value",
ylab="probability")
barplot(res2[,2],names.arg=res2[,1], cex.names=0.7, xlab="portfolio value",
ylab="probability")
par(oma=c(2,2,2,2), mar=c(5,4,2,1))
barplot(res1[,2],names.arg=res1[,1], cex.names=0.7,xlab="portfolio value",
ylab="probability")
barplot(res1[,2],names.arg=res1[,1], cex.names=0.7,xlab="portfolio value",
ylab="probability")
par(mar=c(5,4,2,1))
barplot(res1[,2],names.arg=res1[,1], cex.names=0.7,xlab="portfolio value",
ylab="probability")
par(mar=c(5,4,2,1))
barplot(res1[,2],names.arg=res1[,1], cex.names=0.7,xlab="portfolio value",
ylab="probability")
par(mar=c(5,4,2,1))
barplot(res1[,2],names.arg=res1[,1], cex.names=0.7,xlab="portfolio value",
ylab="probability")
par(mar=c(5,4,2,1))
barplot(res1[,2],names.arg=res1[,1], xlab="portfolio value",
ylab="probability")
x = seq( 4,4,0.1)
F_B = pnorm(x,mean=0,sd=1);
F_A = pnorm(x,mean=0.25,sd=1);
F_AF_B
F_A-F_B
x = seq(-4,4,0.1)
F_B = pnorm(x,mean=0,sd=1);
F_A = pnorm(x,mean=0.25,sd=1);
F_A-F_B
cumsum(F_AF_B)
cumsum(F_A-F_B)
pstar = 0.25 #private probability of winning
odds = 4 #actual odds
p= 1/(1+odds) #house probability of winning
edge = pstar*odds (1 pstar)
pstar = 0.25 #private probability of winning
odds = 4 #actual odds
p= 1/(1+odds) #house probability of winning
edge = pstar*odds-(1-pstar)
f = edge/odds
print(c("p=",p,"pstar=",pstar,"edge=",edge,"f",f))
n = 1000
x = runif(n)
f_over = 1.5*f
f_under = 0.5*f
bankroll = rep(0,n); bankroll[1]=1
br_overbet = bankroll; br_overbet[1]=1
br_underbet = bankroll; br_underbet[1]=1
for (i in 2:n) {
if (x[i]<=pstar) {
bankroll[i] = bankroll[i-1] + bankroll[i-1]*f*odds
br_overbet[i] = br_overbet[i-1] + br_overbet[i-1]*f_over*odds
br_underbet[i] = br_underbet[i-1] + br_underbet[i-1]*f_under*odds
}
else {
bankroll[i] = bankroll[i-1] bankroll[i-1]*f
for (i in 2:n) {
if (x[i]<=pstar) {
bankroll[i] = bankroll[i-1] + bankroll[i-1]*f*odds
br_overbet[i] = br_overbet[i-1] + br_overbet[i-1]*f_over*odds
br_underbet[i] = br_underbet[i-1] + br_underbet[i-1]*f_under*odds
}
else {
bankroll[i] = bankroll[i-1]-bankroll[i-1]*f
br_overbet[i] = br_overbet[i-1]-br_overbet[i-1]*f_over
br_underbet[i] = br_underbet[i-1]-br_underbet[i-1]*f_under
}
}
par(mfrow=c(3,1))
par(mfrow=c(3,1))
plot(bankroll,type="l")
plot(br_overbet,type="l")
plot(br_underbet,type="l")
print(c(bankroll[n],br_overbet[n],br_underbet[n]))
print(c(bankroll[n]/br_overbet[n],bankroll[n]/br_underbet[n]))
source("kelly.R")
ncaa = read.table("ncaa. txt",header=TRUE)
ncaa = read.table("ncaa.txt",header=TRUE)
View(ncaa)
names(ncaa)
d= dist(ncaa[ ,3:14], method="euclidian")
d= dist(ncaa[ ,3:12], method="euclidian")
ncaa_data = as.matrix(ncaa[ ,3:12])
summary(ncaa_data)
round(apply(ncaa_data,2,mean),2)
apply(ncaa_data,2,sd)
library(graphics)
x<- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
+ matrix(rnorm(100, mean= 1, sd = 0.3), ncol = 2))
colnames(x) <- c("x","y")
(cl <- kmeans(x, 2))
plot(x, col = cl$cluster)
library(graphics)
(cl <- kmeans(x, 5, nstart = 25))
plot(x, col = cl$cluster)
points(cl$centers, col = 1:5, pch = 8)
data = read.csv("vc_clust .csv",header=TRUE,sep=",")
data = read.csv("vc_clust.csv",header=TRUE,sep=",")
data = read.csv("vc_clust.csv",header=TRUE,sep=",")
View(data)
dim(data)
names(data)
idx=which(rowSums(is.na(data))==0)
length(idx)
data=data[idx,]
length(idx)
idx=c(3,6,31,32)
length(idx)
names(data)
cdata=data[,idx]
dim(data)
names(cdata)
fit=kmeans(cdata,4)
fit$size
fit$centers
idx=c(25,26,27,28,29,30,31,32)
cdata=data(,idx)
cdata=data[,idx]
names(cdata)
fit=kmeans(cdata,4)
fit$size
fit$centers
#Now,assuming6clusters,we have
fit=kmeans(cdata,6)
fit$size
fit$centers
ncaa=read.table("ncaa.csv", header=TRUE)
ncaa=read.table("ncaa.txt", header=TRUE)
names(ncaa)
fit=kmeans(ncaa[,3:12],4)
fit$size
fit$centers
d = dist(ncaa[,3:14], method="euclidian"
fit = hclust(d, method="ward")
library(stats)
fit = hclust(d, method="ward")
fit = hclust(d, method="ward.D")
d = dist(ncaa[,3:14], method="euclidian")
d = dist(ncaa[,3:12], method="euclidian")
fit = hclust(d, method="ward.D")
names(fit)
plot(fit, main="NCAA_Team")
fit = hclust(d, method="ward.D")
names(fit)
plot(fit, main="NCAA_Team")
groups = cutree( fit, k=4)
rect.hclust( fit, k=4, border="blue")
groups
library(cluster)
clusplot(ncaa[,3;12],groups,color=TRUE,shade=TRUE,labels=2,lines=0)
clusplot(ncaa[,3:12],groups,color=TRUE,shade=TRUE,labels=2,lines=0)
library(rpart)
data("kyphosis")
head(kyphosis)
fit=rpart(Kyphosis~Age+Number+Start,method="Class",data=kyphosis)
fit=rpart(Kyphosis~Age+Number+Start,method="Class",data=kyphosis)
fit=rpart(Kyphosis~Age+Number+Start,method="class",data=kyphosis)
printcp(fit)
summary(fit)
text(fit,use.n=TRUE, all=TRUE, cex=0.8)
plot(fit, uniform = TRUE)
text(fit,use.n=TRUE, all=TRUE, cex=0.8)
dx = 0.001
x = seq(-5,5,dx)
H2 = -sum(dnorm(x,sd=2)*log(dnorm(x,sd=2))*dx)
print(H2)
H3= -sum(dnorm(x,sd=3)*log(dnorm(x,sd=3))*dx)
print(H3)
install.packages("RWeka")
library(RWeka)
library(RWeka)
library(RWeka)
library(RWekajars)
data("cu.summary")
names(cu.summary)
View(cu.summary)
head(cu.summary)
dim(cu.summary)
library(rpart)
fit <- rpart(Mileage~Price +Country + Reliability + Type,
method="anova", data=cu.summary)
summary(fit)
plot(fit, uniform=TRUE)
text(fit, use.n=TRUE, all=TRUE, cex=.8)
plot(fit, uniform=TRUE)
text(fit, all=TRUE, cex=.8)
use.n=TRUE,
plot(fit, uniform=TRUE)
text(fit, use.n=TRUE, all=TRUE, cex=.8)
cahomedata <- data.frame(
MedHouseVal = c(2.34, 3.12, 1.89, 4.56, 3.78, 2.95),
MedInc      = c(3.55, 4.65, 2.85, 6.25, 5.40, 3.90),
HouseAge    = c(15, 30, 25, 10, 18, 40),
AveRooms    = c(6.98, 5.21, 4.32, 7.85, 6.50, 5.10),
AveBedrms   = c(1.02, 0.95, 1.10, 1.20, 1.05, 0.98),
Population  = c(1120, 980, 1430, 2100, 1700, 1350),
AveOccup    = c(2.45, 2.87, 3.10, 2.75, 2.95, 3.20),
Latitude    = c(34.21, 36.77, 37.78, 33.95, 38.58, 34.05),
Longitude   = c(-118.45, -119.42, -122.41, -118.25, -121.49, -118.24)
)
# Write to cahomedata.txt
write.table(cahomedata, file="cahomedata.txt", row.names=FALSE)
write.table(cahomedata, file="cahomedata.txt", row.names=FALSE)
library(tree)
install.packages("tree")
library(tree)
cahomes=read.table("cahomedata.txt", header = TRUE)
fit=tree(log(MedianHouseValue)~Longitude+Latitude,data=cahomes)
View(cahomes)
fit=tree(log(MedHouseVal)~Longitude+Latitude,data=cahomes)
plot(fit)
plot.tree(fit)
plot.tree.sequence(fit)
plot(fit)
library(tree)
price.deciles = quantile(cahomes$MedHouseVal,0:10/10)
cut.prices = cut(cahomes$MedHouseVal,price.deciles, include.lowest=TRUE)
plot(cahomes$Longitude, cahomes$Latitude,
col=grey(10:2/11)[cut.prices] ,pch=20,xlab="Longitude" ,ylab="Latitude")
partition. tree(fit ,ordvars=c("Longitude" ,"Latitude") ,add=TRUE)
plot(cahomes$Longitude, cahomes$Latitude,
col=grey(10:2/11)[cut.prices] ,pch=20,xlab="Longitude" ,ylab="Latitude")
partition.tree(fit,ordvars=c("Longitude","Latitude"),add=TRUE)
plot(cahomes$Longitude, cahomes$Latitude,
col=grey(10:2/11)[cut.prices],pch=20,xlab="Longitude",ylab="Latitude")
partition.tree(fit,ordvars=c("Longitude","Latitude"),add=TRUE)
plot(cahomes$Longitude, cahomes$Latitude,
col=grey(10:2/11)[cut.prices],pch=20,xlab="Longitude",ylab="Latitude")
partition.tree(fit,ordvars=c("Longitude","Latitude"),add=TRUE)
